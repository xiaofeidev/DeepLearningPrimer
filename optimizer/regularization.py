"""
正则化用于减小过拟合的影响

权值衰减：给损失函数加上权重的平方范数(L2 范数)
注意训练的时候损失函数的值是越小越好的，这样就可以抑制权重变大

Dropout： 在每次训练迭代中，以一定的概率 p（通常为0.5）随机选择一部分神经元，并将其输出置为零。
这意味着在每次前向传播中，只有一部分神经元对当前输入进行计算。
在前向传播过程中，丢弃的神经元不参与计算；在反向传播中，只有在保留的神经元上计算梯度。
这样，每个神经元都有机会在训练中被丢弃，模型不会过于依赖于某些特定的神经元。
注意只在训练时丢弃神经元，测试时所有神经元都是参与计算的，只是测试时要将本层的所有神经元输出乘以丢弃率 p
"""